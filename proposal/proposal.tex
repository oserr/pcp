\documentclass[11pt]{article} %\documentclass[journal]{IEEEtran}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{backnaur}
\usepackage[scaled]{beramono}
\usepackage{bm}
\usepackage[small,bf]{caption}
\usepackage[strict]{changepage}
%\usepackage{cite}
\usepackage{dblfloatfix}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{flushend}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{ifsym}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{makeidx}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{pdfpages}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{textcomp}
\usepackage[hyphens]{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{pgfgantt}
\usepackage{wrapfig}
\usepackage{balance}
\usepackage{tikz}
\usetikzlibrary{shapes,decorations}
\usepackage{pgfplots}
\usepgfplotslibrary{units}
\pgfplotsset{compat=1.14}
\usepackage{bm}
\usepackage[
backend=biber,
style=ieee
]{biblatex}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
%\bibliographystyle{IEEEtran}
%\bibliographystyle{acm}
\addbibresource{references.bib}

\addtolength{\evensidemargin}{-.5in}
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\textwidth}{0.8in}
\addtolength{\textheight}{0.8in}
\addtolength{\topmargin}{-.4in}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\vspace{-25pt}
\huge CS 15-618\hfill Project Proposal}
\author{
    Patricio Chilano (pchilano) \\
    Omar Serrano (oserrano)
}
\date{\today}

\begin{document}

\definecolor{beaublue}{rgb}{0.74, 0.83, 0.9}

\lstset{
    language=C++,
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue}\ttfamily,
    stringstyle=\color{red}\ttfamily,
    commentstyle=\color{orange}\ttfamily,
    morecomment=[l][\color{magenta}]{\#},
    breaklines=true
}

\maketitle

\section*{Project Ideas}

We haven't decided on a project idea yet, but have a few ideas that we want to
explore in more depth this week before making a decision. Our goal is to make a
decision and commit to a project idea by Friday, April 6. Our project ideas are:

\begin{itemize}
\item
Parallelizing \texttt{libtomcrypt}
\item
Synchronization mechanisms
\item
Deep learning
\item
GraphRats
\end{itemize}

We haven't yet commited ourselves to one of these ideas, but our focus for this
week is to do some research to flesh out the ideas, determine viability given
the amount of time we have, whether we'll enjoy working on it, and gage what
we'll get out of the experience.

\section*{Parallel libtomcrypt}

\href{https://github.com/libtom/libtomcrypt}{libtomcrypt} is a popular open
source cryptographic library, and our goal would be to parallelize one or more
encryption algorithms in the library.

% What's interesting about it?
This project would be interesting because encryption is a prevalent component in
many computer systems and applications, so there is practical benefit to
speeding up these algorithms. For example, many online services rely on SSL/TLS
for secure communication, and these rely on encryption algorithms. Thus,
speeding up the encryption algorithms can lead to lower-latency service.
Furthermore, it would be particularly satisfying to be able to apply the
concepts we've learned in class to speed-up a popular library that is used in
practice.

% Why is it a suitable project?
One key aspect about this idea that makes it suitable to be a project is the
fact that the performance of the library can be used as a base benchmark,
allowing us to measure our performance by simply measuring the speedup. However,
there are many encryption libraries, so we could also compare the performance of
the algorithms we modify with those of other libraries. Furthermore, encryption
algorithms are not embarrassignly parallel, as can be seen in the small snippted
of code below, which is part of the logic in the AES encryption algorithm, with
clear dependencies between the variables inside the \texttt{for} loop. Parallelizing
these encryption algorithms is very likely not going to be trivial.

\begin{lstlisting}
for (;;) {
    t0 = Te0(byte(s0, 3)) ^ Te1(byte(s1, 2)) ^ Te2(byte(s2, 1)) ^ Te3(byte(s3, 0)) ^ rk[4];
    t1 = Te0(byte(s1, 3)) ^ Te1(byte(s2, 2)) ^ Te2(byte(s3, 1)) ^ Te3(byte(s0, 0)) ^ rk[5];
    t2 = Te0(byte(s2, 3)) ^ Te1(byte(s3, 2)) ^ Te2(byte(s0, 1)) ^ Te3(byte(s1, 0)) ^ rk[6];
    t3 = Te0(byte(s3, 3)) ^ Te1(byte(s0, 2)) ^ Te2(byte(s1, 1)) ^ Te3(byte(s2, 0)) ^ rk[7];

    rk += 8;
    if (--r == 0) {
        break;
    }

    s0 = Te0(byte(t0, 3)) ^ Te1(byte(t1, 2)) ^ Te2(byte(t2, 1)) ^ Te3(byte(t3, 0)) ^ rk[0];
    s1 = Te0(byte(t1, 3)) ^ Te1(byte(t2, 2)) ^ Te2(byte(t3, 1)) ^ Te3(byte(t0, 0)) ^ rk[1];
    s2 = Te0(byte(t2, 3)) ^ Te1(byte(t3, 2)) ^ Te2(byte(t0, 1)) ^ Te3(byte(t1, 0)) ^ rk[2];
    s3 = Te0(byte(t3, 3)) ^ Te1(byte(t0, 2)) ^ Te2(byte(t1, 1)) ^ Te3(byte(t2, 0)) ^ rk[3];
}
\end{lstlisting}

In the case of block ciphers, one clear dimension of parallelization could be
with respect of the mode of operation . The library supports many modes (CBC,
CTR, CFB, ECB, XTS, etc) and some of them present characteristics that make them
suitable for parallelizing encryption/decryption of blocks.  Another important
cryptosystem that could be parallelized is the RSA public-key cryptosystem.
Since it involves modular exponentiation itâ€™s not suitable for fast computation
in the CPU, but its performance could be improved by mapping it to a GPU. This will not be an
original project though since many attempts have already been made to
parallelize the RSA algorithm. \cite{Saxena}

% What we need to resolve before deciding
Before committing ourselves to this project, we want to determine that there are
one or more encryption algorithms amenable to parallelization, and that we can
familiarize ourselves with the code well enough quickly in order to be able to
focus on parallelizing the algorithms rather than simply understanding what is
happening in the code.

Note that we may decide to proceed with the topic of encryption, but to do so
with another library, or to simply create a small library of a few parallel
encryption algorithms that we can then compare with another library.

% Any literatur consulted?

\section*{Synchronization mechanisms}

We are interested in studying and comparing different multi-threading
synchronization mechanisms, including coarse locking, fine-grained locking, and
lock-free techniques.

Out of all the ideas, this is arguably the most likely to have the biggest
payout for us in the long term. As computer engineers, we are bound to face
questions of synchronization at the general purpose CPU level on a weekly, if
not daily, basis. Two examples of questions that we forsee are:

\begin{itemize}
\item
Can we speed up how a server pocesses connections by using a producer-consumer
model with a pool of threads?
\item
We need a thread-safe hash map for the job, but coarse grained locks make the
map too slow. How can we improve its performance?
\end{itemize}

This project will prepare us to answer these questions, and will provide an
opportunity to enhance our skills to analyze multi-threading synchronization
problems, and to develop high performing concurrent data structures.

If we were to go this route, our tentative plan is to implement a few concurrent
data structures with coarse and fine-grained locking, and lock-free
synchronization mechanisms, to compare the performance of these techniques, and
to compare the performance of our data structures with another library, or
programming language. We would probably implement a singly linked list, doubly
linked list, and hash map, but would also be interested in looking at other
data structures, such as a self-balancing binary tree (e.g., red-black tree).

In our analysis, we would look at how the different techniques compare with each
other. To do this, we would create tests that use different numbers of threads,
and possibly run the expriments on different machines. We would also compare our
implementation with another library, or programming language. For example, we
would probably create some tests to compare with Java's concurrent data
structures, but in addition maybe also another library (e.g.,
\href{https://github.com/khizmax/libcds}{libcds}, which claims to use concurrent
lock-free data structures).

We are currently aware of three papers \cite{Harris, Fomitchev, Maged} that we
can use to guide our implementation, experimentation, and analysis. We'll
probably look at these papers more this week before making a decision, but we'll
rely on them if we decide to pursue this project.

\section*{Deep learning}

We are interested in learning to implement parallel deep learning algorithms,
learning how different forms of parallelism affect performance, and how parallel
deep learning compares with sequential deep learning.

This is an interesting project because deep learning techniques have achieved
unprecedented success in machine learning tasks within the last few years, and
the problem of deep learning presents both opportunities, and challenges, for
parallelization. There are aspects of deep learning, such as operations accross
different units of a layer, that are easily parallelized, but there are other
aspects that present serious challenges, including the fact that stochastic
gradient descent, the optimization algorithm used to learn the parameters of a
neural network, is inherently sequential, i.e., the computation at step $t+1$
depends on the results of the computation at step $t$. And even though it is
well understood that state of the art implementations of deep learning use GPUs
and cluster computing, there is still a compelling incentive to find
implementations of deep learning that work in single node mode, and that are
parallel and efficient, given the trend toward edge-computing, where more of the
computing moves from the cloud to the edge, close to the source of data.

If we decide to go this route, our tentative plan is to implement a serial
convolution neural network (CNN), a multi-threaded version, and a GPU version,
making use of \href{https://developer.nvidia.com/cudnn}{cuDNN}, CUDA's deep
neural network library. We wouldn't simply implement a CNN, but rather a
\href{https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html}
{DeepDream} CNN. Ultimately, we would compare the performance of these
implementations, in terms of speed and accuracy. Some nice to {\it have}s would
be:

\begin{itemize}
\item
Implementing a distributed version of the CNN.
\item
For a given CNN architecture, to compare the performance of our implementation
with that of an open source library, e.g., \href{http://pytorch.org/}{PyTorch}.
\end{itemize}

One of us has experience with neural networks, but neither one of us have
experience with CNNs in particular, so we would consult \cite{DL,PDDL,DBLP,Dean}
to learn how to implement CNNs, and to do so in parallel. This project idea is
very interesting, but it contains some serious challenges, so we'll spend some
time in the next few days trying to determine the viability of the project, in
particular understanding the challenge of implementing a CNN for the CPU and
GPU.

\section*{More fun with GraphRats!}

We like GraphRats because there are a lot of different parallelization avenues
we can explore. We almost certainly would map GraphRats to the GPU, but we would
also be interested in doing any of the following:

\begin{itemize}
\item
Map GraphRats to the Xeon Phi cores.
\item
Map GraphRats to ISPC.
\item
Use MPI on more than one machine, in combination with multi-threading, with the
possibility of exploring performance on larger workloads, e.g., larger graphs
with more rats.
\item
Extreme speedup: combine MPI, multi-threading, and vector instructions.
\end{itemize}

One of the benefits of working on GraphRats is that we are already familiar with
the code, so we can jump directly into mapping the code to GPU, or to exploit
some other parallelization technique. Furthermore, we would be able to dive
deeper into why some changes work and others don't, allowing us to produce a
final report with more empirical analysis.

\printbibliography

\end{document}

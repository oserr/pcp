\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{backnaur}
\usepackage[scaled]{beramono}
\usepackage{bm}
\usepackage[small,bf]{caption}
\usepackage[strict]{changepage}
\usepackage{dblfloatfix}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{flushend}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{ifsym}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{makeidx}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{pdfpages}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{textcomp}
\usepackage[hyphens]{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{pgfgantt}
\usepackage{wrapfig}
\usepackage{balance}
\usepackage{tikz}
\usetikzlibrary{shapes,decorations}
\usepackage{pgfplots}
\usepgfplotslibrary{units}
\pgfplotsset{compat=1.14}
\usepackage{bm}
\usepackage[
backend=biber,
style=ieee
]{biblatex}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
%\bibliographystyle{IEEEtran}
%\bibliographystyle{acm}
\addbibresource{references.bib}

\newcommand{\rt}{\textsuperscript{\textregistered}}
\newcommand{\tm}{\texttrademark}

\addtolength{\evensidemargin}{-.5in}
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\textwidth}{0.8in}
\addtolength{\textheight}{0.8in}
\addtolength{\topmargin}{-.4in}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\vspace{-25pt}
\huge CS 15-618 Project Proposal \\
\huge Synchrony
}
\author{
    Patricio Chilano (pchilano) \\
    Omar Serrano (oserrano)
}
\date{\today}

\begin{document}

\definecolor{beaublue}{rgb}{0.74, 0.83, 0.9}

\lstset{
    language=C++,
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue}\ttfamily,
    stringstyle=\color{red}\ttfamily,
    commentstyle=\color{orange}\ttfamily,
    morecomment=[l][\color{magenta}]{\#},
    breaklines=true
}

\maketitle

\section*{Summary}
We are going to implement a concurrent doubly-linked list, and a hash map,
lock-free, and with coarse-grain and fine-grain locks, in order to
investigate how these concurrent data structures are implemented, and to study
first-hand how these techniques compare with each other on a variety of
different workloads.

\section*{Background}
Even though some parallel applications may get away without needing concurrent
data structures, arguably the more common paradigm is for threaded applications
to use them. Work queues, for example, are a good way for a server to model the
producer-consumer paradigm, as the server puts newly created connections into a
queue, and a pool of threads take items from the queue as they are added to it.
A parallel implementation of $A^*$ may need a concurrent hash set to record the
nodes that have already been visited.

The common theme of these examples is the need for thread-safe data structures,
yet both present different use cases of concurrency, and hence the best type of
synchronization mechanism for a set of applications may be different. The
server, for example, may be better served by a blocking queue. $A^*$, on the
other hand, might perform better with a fine-grain or lock-free hash set.

Thus, our goal is to gain experience applying different synchronization
techniques, and to recognize how these strategies behave with different
workloads. Even though we are only experimenting with linked lists and hash
maps, we hope that the insights gained from these experiments can be transferred
to other problem settings.

\section*{Challenge} 
One of the challenging points about this project is to be
able to minimize serialization among threads operating on the proposed data
structures, i.e. double link lists and hash maps, so that performance not only
increases with parallelization but also scales as the number of cores used are
increased. When benchmarking our implementation we will assume each thread will
have a bunch of operations to perform on a given data structure, independent of
the other threads, so although no special communication will be needed we will
have to ensure proper synchronization among them to maintain the invariants of
each data structure. We will use techniques such as fine grain locking and lock-
free programming, both of which present its own challenges.

Fine grain locking can reduce contention compared with using a single global
lock, but complicates correctness of the program, since deadlock, livelock and
races can be harder to detect. Also techniques such as “hand-over-hand” locking
not only add additional overhead of taking locks in each step, but could also
force threads to wait on each other even if they need to modify opposite sides
of a list. This is particularly true when a thread that acquires a lock close to
the head of a list is descheduled by the OS, forcing all other threads that
start a new modification to possibly wait for it. This blocking characteristic
of locks is a big disadvantage and one of the motivations to use lock-free
techniques.

In the case of lock-free programming, the main challenge will be ensuring
correctness of the implementation since it is not only trickier to implement due
to issues such as the ABA problem or accessing freed memory, but also by having
to ensure sequential consistency in dealing with the memory model of the CPU
architecture and compiler optimizations. Also although we are not using locks,
there is still contention in the memory bus due to loops that use atomic
operations such as the CAS operation, which can significantly slow down
performance.

By completing this project we hope to understand the challenges mentioned above
and be able to gain intuition in which synchronization mechanism is more
suitable to a particular application, given the workload and number of threads
involved. This skill will be helpful in future projects in order to decide which
technique should we used when parallelizing an application in order to achieve
maximum performance.

\section*{Platform Choice}
We are using C/C++ to implement the concurrent data structures. We believe this
is the best choice in terms of the flexibility with respect to design
choices, and it is almost a necessary choice when it comes to lock-free
mechanisms, because the language needs to provide an interface for direct memory
access. There are other programming languages that will also provide direct
memory access, such as \href{https://golang.org/}{golang} and
\href{https://www.rust-lang.org/en-US/}{rust}, but C/C++ also provides a direct
interface to the OS threading infrastructure, i.e., \texttt{Pthreads}, thus
allowing us to tinker with the system at the lowest level of the software/hardware
interface. More specifically, we are planning to use the C++11 standard, which
introduced threads to C++, and we'll be making heavy use of the tools in
\href{http://en.cppreference.com/w/cpp/header/thread}{\texttt{<thread>}},
\href{http://en.cppreference.com/w/cpp/header/mutex}{\texttt{<mutex>}}, and
\href{http://en.cppreference.com/w/cpp/header/atomic}{\texttt{<atomic>}}.

We are planning to run all of our experiments on Posix OSes, such as Linux or
macOS, running x86\_64. The x86\_64 architecture is more modern than other
system architectures and we may run into a problem where we need a
synchronization or memory model feature only found in this architecture. Linux
and macOS are good choices for us to implement our data structures, because they
are Posix OSes, provide the familiar \texttt{Pthreads} abstraction/interface,
and are programmer-friendly. Furthermore, these platforms are the most
convenient for us, because GHC machines and the latedays cluster are Linux
x86\_64, and our laptops are macOS x86\_64.

We are also planning to use Java in order to compare the performance of our data structures with Java's
\href{https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentHashMap.html}{ConcurrentHashMap} and
\href{https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentLinkedDeque.html}{ConcurrentLinkedDeque}.
Despite the differences between Java and C++, these Java concurrent data
structures are a good choice to compare with our library, because Java's
concurrent library is a mature library, is well known, and it is implemented by
experts in their field.

\section*{Resources}

\subsection*{Code/Libraries/Compilers}
The point of our project is to implement concurrent data structures, so we'll
build our library from scratch. Given that we'll compare our library with Java's
concurrent package on our macs, the GHC machines, and the latedays cluster,
we'll use Java and GCC. To test our data structures for correctness, we will use
the \href{https://github.com/google/googletest}{GoogleTest} library for unit
testing. Per Table~\ref{table:compiler}, the machines we'll be using have
different compiler and Java runtime environments.

\begin{table}[t]
\begin{center}
\begin{tabular}{llll}
\toprule
\bf Machine(s) & \bf C++ & \bf Java \\
\midrule
GHC            & gcc 4.9.2 & OpenJDK 8 \\
latedays       & gcc 4.9.2 & Oracle 8 \\
macOS          & gcc 6.4 & Oracle 10 \\
\bottomrule
\end{tabular}
\caption{Compiler and Java RE toolchains we will use for our experiments.}
\label{table:compiler}
\end{center}
\end{table}

% machines
\subsection*{Machines}
We've yet to choose the machines where we'll carry our experiments, but we'll
probably settle on one GHC machine, a machine on the latedays cluster (via
\texttt{qsub -q @server}), one of our laptops, and, if time permits, the Phi
Cores. These are a good sample of machines to test our concurrent data
structures, because they have different specs and this will allow us to see how
the data structures scale and perform under different conditions/environments.
The specs for these machines are listed in Table~\ref{table:specs}. Particular
points of interest specific to the specs of the machines we are planning to use
are:

\begin{itemize}
\item
macOS has the least number of cores, but it has the most modern and powerful
cores. How do our data structures scale from 1 to 8 threads on the macOS
compared with the other machines?
\item
GHC machines have 16 virtual cores, more than the mac, but less than machines in
the latedays cluster; however, machines in the latedays cluster are dual socket,
whereas GHC machines are single socket. How does this affect the scaling
behavior, in particular when ramping up from 12 to 16 threads?
\item
At 61 cores, the Phi Cores offer, by far, the highest level of parallelism and
number of threads. How do our data structures scale at this level of parallelism?
\end{itemize}

\begin{table}[t]
\begin{center}
\begin{tabular}{llll}
\toprule
\bf Machine(s) & \bf Specs & \bf Cores & \bf Threads   \\
\midrule
GHC            & Intel\rt Xeon\rt CPU E5-1660 v4 @ 3.20GHz & 8 & 16 \\
latedays       & Intel\rt Xeon\rt CPU E5-2620 v3 @ 2.40GHz & 6 & 12 \\
macOS          & Intel\rt Core\tm i7-7700HQ @ 2.80GHz & 4 & 8 \\
Phi Cores      & SomeSpecs & Some\# & Some\# \\
\bottomrule
\end{tabular}
\caption{Specs of machines we plan to use for experiments.}
\label{table:specs}
\end{center}
\end{table}

\subsection*{Papers/Book}
We will start our research into the implementation of high performance
concurrent data structures with \cite{Harris, Fomitchev, Maged, Williams}.
\cite{Harris, Fomitchev} seem to focus exclusively on non-blocking
lists, but whatever we learn here can also be applied to a concurrent hash map,
because a hash map is built-up as buckets of lists; however, \cite{Maged} delves
into the topic of lock-free hash tables, so we'll be able to get more insights
about how to build a lock-free hash map from lock-free linked lists.
\cite{Williams} is a tutorial book, and it will be very useful to us because it
focuses explicitly on using the threading primitives provided by C++11 to build
concurrent applications, and it includes examples of fine-grained blocking and
non-blocking data structures.

\section*{Goals and Deliverables}  
Plan to achieve: 
\begin{itemize} 
\item
Implement an ordered concurrent doubly linked list using different
synchronization methods: course- grain locks, fine-grain locks and lock-free
techniques. 
\item Compare the performance of each implementation of the doubly
linked list against each other and against the serial version with respect to
the number of threads. 
\item Compare the performance of each implementation of
the doubly linked list against the Java implementation(??). 
\item Implement a
concurrent HashMap using different synchronization methods: course-grain locks,
fine-grain locks  and lock-free techniques. 
\item Compare the performance of
each implementation of the HashMap against each other and against the serial
version with respect to the number of threads. 
\item Compare the performance of
each implementation of the HashMap against the Java ConcurrentHashMap data
structure.
\end{itemize}

Desirables: 
\begin{itemize}
\item
Compare fine-grain locking implementations using different locks
(spinlocks and mutexes) to see how busy-waiting performs against a blocking
lock.
\end{itemize}

Although it’s hard to set a particular speedup goal we expect that the fine-
grain locking and lock-free implementations provide good performance with
respect to the serial version, especially the latter one with increasing number
of threads. The main idea of this project though is to gain insight into which
of these techniques is better suited for a particular scenario, i.e. some of the
questions we would like to answer are: How well each of these methods scale with
increasing number of threads? Which synchronization method is preferred with
respect to number of threads? What’s the biggest factor that prevents linear
scaling in each case?

We will create benchmarks that perform a number of insert and delete operations
for both data structures. We will measure the time taken to complete all of them
by each implementation for a given data structure and calculate a speedup with
respect to the serial version. By varying the number of threads we can create
graphs that tells us how well each of these implementations scale with number of
threads and how they compare with each other. In order to ensure that insertions
and deletions do not corrupt the data structures, we will also create harness
tests that compare the final state of a run with some references created
earlier.

In terms of presentation, we will create graphs that show how well each of the
implementations for a given data structure scale with increasing number of
threads, and how they compare against each other and against the Java
implementation for that same data structure.

\section*{Schedule}
The detailed weekly schedule that we have planned for now is found in
Table~\ref{table:sche}. The schedule includes four weeks, but can also be
divided into three sections: what we hope to accomplish by each of the first two
checkpoints, and before submitting the final report. At a high lovel, our goal
is to have coarse-grain lock tasks by the first checkpoint, fine-grain lock
tasks by the second checkpoint, and to finish lock-free tasks the last week and
a half, before the final deadline. Note also that the lock-free list is included
in the week of 4/23 and 4/30 to reflect our belief that this will be the most
challening task. The final two items are desirable items, i.e., items marked
with a star, and it would be nice to get to them, but it is unlikely that we'll
do so.

\begin{table}[t]
\begin{center}
\begin{tabular}{ll}
\toprule
\bf Week & \bf Deliverable   \\
\midrule
4/9      & Project proposal \\
         & Doubly-linked list with coarse-grain locks \\
         & Regression unit tests for linked lists \\
4/16     & Hash map with coarse-grain locks \\
         & {\bf Check point 1} \\
         & Doubly-linked list with fine-grain locks \\
         & Hash map with fine-grain locks \\
         & Benchmarking harness for linked-lists \\
         & Regression unit tests for hash map \\
4/23     & Benchmarking harness for hash maps \\
         & Benchmarks for linked lists with coarse- and fine-grain locks \\
         & Benchmarks for hash maps with coarse- and fine-grain locks \\
         & {\bf Check point 2} \\
         & Lock-free doubly-linked list \\
         & Benchmarks for Java ConcurrentLinkedDeque \\
4/30     & Benchmarks for Java ConcurrentHashMap \\
         & Lock-free doubly-linked list \\
         & Lock-free hash map \\
         & Benchmark for lock-free linked list \\
         & Benchmark for lock-free hash map \\
         & Final report \\
         & *Lock-free ordered doubly-linked list \\
         & *Concurrent data structures with spinning locks \\
\bottomrule
\end{tabular}
\caption{
Weekly schedule. Check points include the items preceding them. The * on the
last two items indicate {\it nice-to-haves}, but we are not commiting to them.
}
\label{table:sche}
\end{center}
\end{table}

\printbibliography

\end{document}

\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{backnaur}
\usepackage[scaled]{beramono}
\usepackage{bm}
\usepackage[small,bf]{caption}
\usepackage[strict]{changepage}
\usepackage{dblfloatfix}
\usepackage{enumerate}
\usepackage{enumitem}
\usepackage{flushend}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{ifsym}
\usepackage{lipsum}
\usepackage{listings}
\usepackage{makeidx}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{pdfpages}
\usepackage{subcaption}
\usepackage{setspace}
\usepackage{textcomp}
\usepackage[hyphens]{url}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{xcolor}
\usepackage{pgfgantt}
\usepackage{wrapfig}
\usepackage{balance}
\usepackage{tikz}
\usetikzlibrary{shapes,decorations}
\usepackage{pgfplots}
\usepgfplotslibrary{units}
\pgfplotsset{compat=1.14}
\usepackage{bm}
\usepackage[
backend=biber,
style=ieee
]{biblatex}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=cyan,
}
\addbibresource{references.bib}

\newcommand{\rt}{\textsuperscript{\textregistered}}
\newcommand{\tm}{\texttrademark}

\addtolength{\evensidemargin}{-.5in}
\addtolength{\oddsidemargin}{-.5in}
\addtolength{\textwidth}{0.8in}
\addtolength{\textheight}{0.8in}
\addtolength{\topmargin}{-.4in}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{\vspace{-25pt}
\huge CS 15-618 Project Report \\
\huge Synchrony (ID 24)
}
\author{
    Patricio Chilano (pchilano) \\
    Omar Serrano (oserrano)
}
\date{\today}

\begin{document}

\definecolor{beaublue}{rgb}{0.74, 0.83, 0.9}

\lstset{
    language=C++,
    basicstyle=\ttfamily\scriptsize,
    keywordstyle=\color{blue}\ttfamily,
    stringstyle=\color{red}\ttfamily,
    commentstyle=\color{orange}\ttfamily,
    morecomment=[l][\color{magenta}]{\#},
    breaklines=true,
    morekeywords={nullptr,noexcept},
    xleftmargin=.1\textwidth,
    xrightmargin=.1\textwidth,
}

\maketitle

\section{Summary}
We implemented a set of serial and concurrent linked lists and hash maps using
different synchronization mechanisms, including coarse-grained locks,
fine-grained locks, fine-grained spinning-reader-writer locks, and lock free. We
then compared the performance of these data structures under different
use-profiles. Finally, we compared the performance of our hash maps with Intel's
Thread Building Block's (TBB) and libcuckoo's concurrent hash maps under different
use-profiles.

\section{Background}

\subsection{Linked List} \label{ssec:bglist}
Linked lists are a simple data structure that is simply made up of zero or more
nodes connected in serial via pointer links, where each node contains a data
value, and a link to the next node. The basic operations they support are
insertion, removal, and lookup. Insertions take an input data value, create a
new node with the data value, and insert the node somewhere in the list,
typically the front or back of the list. Removals take an input data value,
search for a node containing the item, and remove the node from the list.
Lookups take an input data value, search for a node containing the value, and
return a reference/pointer to the data value or the node containing the value.

Linked lists are not inherently parallel, because typically operations begin at
the head of the list, and so there is an intrinsic bottleneck; however,
enhancing a linked list's concurrency is still worthwhile the effort because
they are convenient to use and are often the foundation for other data
structures which we might also need to be concurrent, such as stacks, queues,
hashmaps, skip-lists, etc. Furthermore, many algorithms rely on {\em list-like}
data structures, e.g., depth-first search uses a stack for the list of nodes in
the frontier, and to make them concurrent it may be necessary to start with the
list. Note the emphasis on {\em list-like}, because in some cases it may be
preferable to use an array.

The first concern in making a list concurrent is making it thread-safe. This is
easliy accomplished by locking the whole list for any operation, but prevents us
from exploiting parallelism. Despite the lack of a parallel-friendly nature,
there is still plenty of opportunity to parallelize operations on a linked list,
especially if different threads work on different nodes. Ideally, read-only
operations should be completely parallel, but even modify operations can be
parallel if nodes to be modified are not neighbors. Ultimately, to parallelize
operations on a linked list we must use some kind of synchronization technique
to avoid corrupting the list.

Thus, we looked at the following techniques, each of which, in theory, has its
own set of advantages and disadvantages:

\begin{itemize}
% Coarse grain locks
\item Coarse grain locks
\begin{itemize}
\item Advantages
\begin{itemize}
\item Eeasy to implement.
\item Only one lock per list. From a resource perspective, this is an advantage.
\end{itemize}
\item Disadvantages
\begin{itemize}
\item Locks the whole list, removing opportunities for parallelization.
\end{itemize}
\end{itemize}

% Fine grain locks
\item Fine grain locks
\begin{itemize}
\item Advantages
\begin{itemize}
\item More opportunities for parallelization, since only nodes are locked.
\end{itemize}
\item Disadvantages
\begin{itemize}
\item
More difficult to implement than coarse-grain locks, because locking occurs on
every node-hop.
\item
The number of locks is linear with the lenght of the list, requiring more
resources.
\item
Traversing the list is more expensive and less efficient, because node-hops
requires getting a hold of a lock.
\end{itemize}
\end{itemize}

% Spinning locks
\item Fine-grained spinning reader-writer locks
\begin{itemize}
\item Advantages
\begin{itemize}
\item More opportunities for parallelization, since only nodes are locked.
\item
May lead to better performance if it is to the application's advantage to not
have threads descheduled by the operating system, or if increased bus contention
does not affect appliction adversely.
\item
Potentially greater parallelism than fine-grained locks because nodes can have
multiple readers.
\end{itemize}
\item Disadvantages
\begin{itemize}
\item
More difficult to implement than coarse-grain locks, but same level of
difficulty as plain fine-grained locks.
\item
The number of locks is linear with the lenght of the list, requiring more
resources.
\item
Traversing the list is more expensive and less efficient, because node-hops
requires getting a hold of a lock.
\item
May lead to worse performance if it is to the application's disadvantage to not
have threads descheduled by the operating system, or if increased bus contention
affects the appliction adversely.
\item
Potentially greater chance of starvation for writers if system has few writers
and many readers.
\end{itemize}
\end{itemize}

% Lock free
\item Lock free
\begin{itemize}
\item Advantages
\begin{itemize}
\item Best opportunities for parallelization, since nothing is locked.
\item
Potentially zero additional cost in terms of resources, since nodes do not
require locks.
\end{itemize}
\item Disadvantages
\begin{itemize}
\item
More difficult to implement than fine-grained locks, because nothing is locked,
and must use atomic CAS operations, which are difficult to reason about.
\item
Traversing the list is slightly more expensive than with coarse-grained locks,
since atomic CAS must be used along the way.
\end{itemize}
\end{itemize}
\end{itemize}

\section{Technologies used}
\subsection{Language}
We used C++11 because it would allow us to work at a high level of abstraction,
making it easy for us to think about lists and nodes as objects, while also
allowing us to work close to the metal, allowing us to control memory allocation
and directly reference memory addresses. Furthermore, C++11 overloaded operators
makes it easy to work with atomic primitives, and this proved useful for
implementing a spinning-reader-writer lock, and the lock-free list.

\subsection{Target machines}
Our target machines were latedays cluster and GHC machines, because they are
x86-64, use the Linux operating system, and support a decent number of threads,
enough to see clear patterns in our experiment results.

% Mention that we did not use a specific machine on the latedays cluster, and
% Omar used ghc 28. Which one did Patricio use?

\subsection{External libraries}
In addition to comparing the different synchronization techniques we also wanted
to compare our concurrent data structures with an external library to get an
idea of the caliber of our implementation, and ofcourse for fun as well! We were
not able to find in time a library that implemented a plain vanilla concurrent
linked list (TBB implements concurrent deques and vectors, but not a list), but
we did compare TBB's and libcukoo's concurrent hash map with ours.

% Also used GoogleTest lib

\section{Approach}

\subsection{Overview}
At a high level, our approach consisted of the following steps:
\begin{enumerate}
\item
Implement a serial linked list.
\item
Implement a template hashmap where the bucket type is parametrized.
\item
Implement concurrent linked lists with the synchronization mechanisms listed in
section~\ref{ssec:bglist}.
\item
Create hashmaps with different bucket types by plugging in the lists to the
template hashmap.
\item
Create serial and asynchronous correctness tests for the lists and hashmaps.
\item
Create a benchmarking harness to test the lists and hashmaps, including TBB and
libcuckoo hashmaps, with different use-profiles.
\end{enumerate}

\subsection{Implementing serial linked list}
The most important aspect of our serial linked list is the interface we chose to
implement, depicted in figure~\ref{fig:dllist}. Our goal was to make it simple
to test insertions, lookups, and removals, and we used the same interface with
the concurrent lists. The member function names are self-explanatory. The
difference between {\tt Insert} and {\tt InsertUnique} is that the former
inserts elements at the head of the list, while the latter traverses the list to
the end, and inserts an element at the tail of the list {\em only} if the
element is not found. The purpose of {\tt InsertUnique} is to be used for
hashmap insertion, thus preserving a hashmap's invariant of unique keys.

\begin{figure}
\begin{center}
\begin{lstlisting}[numbers=left]
template <typename T> struct DlList {
  virtual ~DlList();
  virtual DlNode<T> *Insert(T value);
  virtual bool InsertUnique(T value);
  virtual bool Remove(T value) noexcept;
  virtual bool Contains(T value) const noexcept;
};
\end{lstlisting}
\caption{Serial linked list interface. Some details have been omitted.}
\label{fig:dllist}
\end{center}
\end{figure}

\subsection{Implementing template hashmap}
Figure~\ref{fig:hashmap} contains the part of the interface that we tested in
the benchmarks. The two relevant aspects are that the bucket type is
parametrized by template {\tt TList}, and that the number of buckets can be
configured at runtime. We used C++ {\tt std::hash} template to compute key
hashes. Other than think wrappers for TBB's and libcuckoo's hashmaps, we did not
have to create any other hashmaps because we were able to parametrize the hash
map with all of the concurrent lists we implemented.

\begin{figure}
\begin{center}
\begin{lstlisting}[numbers=left]
template <typename K, typename V, template <typename> class TList>
struct HashMap {
  std::unique_ptr<TList<Element>[]> buckets;
  HashMap(size_t nBuckets)
      : buckets(new TList<Element>[nBuckets]), nBuckets(nBuckets) {}
  bool Insert(K key, V value);
  bool Remove(K key);
  bool Has(K key) const noexcept;
};
\end{lstlisting}
\caption{Partial interface for serial hashmap.}
\label{fig:hashmap}
\end{center}
\end{figure}


\section{Results}

\section{Conclusion}

\section{Division of Work}
Equal work was performed by both partners.

%lateday_combined_list_insert_10_lookup_10_removal_80.png
%lateday_combined_list_insert_10_lookup_80_removal_10.png
%lateday_combined_list_insert_25_lookup_25_removal_50.png
%lateday_combined_list_insert_25_lookup_50_removal_25.png
%lateday_combined_list_insert_50_lookup_25_removal_25.png
%lateday_combined_list_insert_80_lookup_10_removal_10.png

%lateday_combined_map_insert_10_lookup_10_removal_80.png
%lateday_combined_map_insert_10_lookup_80_removal_10.png
%lateday_combined_map_insert_25_lookup_25_removal_50.png
%lateday_combined_map_insert_25_lookup_50_removal_25.png
%lateday_combined_map_insert_50_lookup_25_removal_25.png
%lateday_combined_map_insert_80_lookup_10_removal_10.png

\begin{figure}[h]
\centering
\includegraphics[width=1.0\linewidth]{figs/lateday/combined/lateday_combined_list_insert_10_lookup_10_removal_80}
\caption{Fig.}
\label{fig:fig1}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.5\linewidth]{figs/lateday/combined/lateday_combined_map_insert_10_lookup_10_removal_80}
\caption{Fig.}
\label{fig:fig2}
\end{figure}

\printbibliography

\end{document}
\grid
